Docker command:

docker logs [conatiner-id] :
	show the messages from the main running process in the conatiner
	
docker exec -it [container-id] /bin/bash:
	get a interactive shell from the running container
	
docker cp:
	copy files between host and conatiner
	
docker inspect:

docker ports

running docker within weave network
1. launch weave if not on the node:
   weave launch --dns-domain="ienergy.devcommunity." 172.31.54.85 (the ip address is the master node, and we are using the domain as set)
2. setup the weave environment variable
   eval $(weave env)
3. start the container and point to the consul hostname defined within the weave network, you can give it a host name for service discovery
   docker run -d -h state -p 8080:8080 -e CONSUL_HOST_NAME=consul.ienergy.devcommunity -e CONSUL_HOST_PORT=8500 kchen007/state
4. you can start another state micro service on another machine or the same machine, with the same HOSTNAME, like above
   docker run -d -h state -p 8080:8080 -e CONSUL_HOST_NAME=consul.ienergy.devcommunity -e CONSUL_HOST_PORT=8500 kchen007/state
5. what will happen is that weave DNS will return both ipaddress for the host name "state" alternatively. if you have more, it will do the round robin to return each ipaddress.
6. with this, we can use nginx docker container as reverse proxy and load balance to dispatch request among all the state micro-service container with the same host name. 
7. the /etc/nginx/nginx.conf will looks like this, we need create a new container to copy the file
       location /statems/ {
        proxy_pass http://state:8080/;
       }
   http://nginx_host_public_ip/statems/v1/state/key will redirect the request to one of the actual state microservice.
8. to be able to use the weave DNS to look up the hostname, the nginx container also need to run within the weave network. 

running docker web app behind nginx with load banlancer(the nginx is running on the host level, not inside container, it will not have access to weave DNS)
  a simple configuration looks like:
  http {
  	upstream mystates {
  		server host1:port;
  		server host2:port;
  	}
  	
  	server {
  		listen 80;
  		server_name localhost;
  		
  		location /statems/ {
  			# the ending slash is important,
  			# without the ending /, it will forward /statems/.... as part of url to the real server.
  			# with the ending /, it will strip the /statems, just send the rest to the real server.
  			# for example, use put http://nginxserver/statems/v1/.....
  			# with the ending /, the request will be http://host1:port/v1/....
  			# otherwise, it will be http://host1:port/statems/v1/.....
  			proxy_pass http://mystates/; 
  		}
  }

Swagger editor from an existing project:
E:\aws-related\swagger-project\hello-world>swagger project edit

# curl to the Singluarity 
 curl -i -X POST -H "Content-Type: application/json" -d @docker_hello_world.json http://localhost:7099/singularity/api/deploys 

# curl to my nodejs web server, the elment should be message="deploy object" 
 curl -i -X POST -H "Content-Type: application/json" -d @nodejs_post.json http://localhost:8787/submit 

# curl with proxy, if the password contains @, put "" around it.
E:\aws-related\mesos-frame-work-jobs>curl --proxy http://np1prxy801.corp.halliburton.com:80 --proxy-user userName:password -X POST -H "Content-Type: application/json" -d @nodejs_post.json http://52.91.164.216:8787/submit

# git with proxy
  git config --global http://np1prxy801.corp.halliburton.com:80
centos instllation:
always run this:
   sudo yum install epel-release

1. x2go server
	sudo yum -y install x2goserver x2goserver-xsession
	
2. node.js:
	sudo yum -y nodejs npm
	
	
3. swagger
   npm install swagger
   
4. git
   sudo yum -y install git
 
